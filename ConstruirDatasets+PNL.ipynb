{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "copyrighted-round",
   "metadata": {},
   "source": [
    "# Construir Dataset + Preprocesamiento PNL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "systematic-accounting",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition  import LatentDirichletAllocation\n",
    "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "bottom-regression",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path actual:  /home/iciac/Escritorio/CursoIA/AprendizajeNoSupervisado\n"
     ]
    }
   ],
   "source": [
    "# Actual dir\n",
    "path = \"dataset\"\n",
    "if path not in os.getcwd():\n",
    "    os.chdir(os.getcwd()) \n",
    "\n",
    "path_actual =     os.getcwd()\n",
    "print(\"Path actual: \",path_actual)\n",
    "df = pd.read_csv(os.getcwd()+\"/dataset/okcupid_profiles.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "quiet-elephant",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>height</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>59946.000000</td>\n",
       "      <td>59943.000000</td>\n",
       "      <td>59946.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>32.340290</td>\n",
       "      <td>68.295281</td>\n",
       "      <td>20033.222534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>9.452779</td>\n",
       "      <td>3.994803</td>\n",
       "      <td>97346.192104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>18.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>26.000000</td>\n",
       "      <td>66.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>30.000000</td>\n",
       "      <td>68.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>37.000000</td>\n",
       "      <td>71.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>110.000000</td>\n",
       "      <td>95.000000</td>\n",
       "      <td>1000000.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                age        height          income\n",
       "count  59946.000000  59943.000000    59946.000000\n",
       "mean      32.340290     68.295281    20033.222534\n",
       "std        9.452779      3.994803    97346.192104\n",
       "min       18.000000      1.000000       -1.000000\n",
       "25%       26.000000     66.000000       -1.000000\n",
       "50%       30.000000     68.000000       -1.000000\n",
       "75%       37.000000     71.000000       -1.000000\n",
       "max      110.000000     95.000000  1000000.000000"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Variables continuas\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "later-drive",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valores Nulos \n",
      "-----------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "age                0\n",
       "status             0\n",
       "sex                0\n",
       "orientation        0\n",
       "body_type       5296\n",
       "diet           24395\n",
       "drinks          2985\n",
       "drugs          14080\n",
       "education       6628\n",
       "ethnicity       5680\n",
       "height             3\n",
       "income             0\n",
       "job             8198\n",
       "last_online        0\n",
       "location           0\n",
       "offspring      35561\n",
       "pets           19921\n",
       "religion       20226\n",
       "sign           11056\n",
       "smokes          5512\n",
       "speaks            50\n",
       "essay0          5488\n",
       "essay1          7572\n",
       "essay2          9638\n",
       "essay3         11476\n",
       "essay4         10537\n",
       "essay5         10850\n",
       "essay6         13771\n",
       "essay7         12451\n",
       "essay8         19225\n",
       "essay9         12603\n",
       "dtype: int64"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Valores Nulos \\n-----------\")\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fewer-harvard",
   "metadata": {},
   "source": [
    "## Prepocesamiento PNL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "molecular-wesley",
   "metadata": {},
   "source": [
    "Existen nueve columnas que describen los gustos de los usuarios, las hemos juntado para tratar de extraer los temas principales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "angry-proceeding",
   "metadata": {},
   "outputs": [],
   "source": [
    "essaysname = [\"essay\"+str(i) for i in range(0,10)]\n",
    "profiles = df[essaysname].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "urban-bouquet",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay0</th>\n",
       "      <th>essay1</th>\n",
       "      <th>essay2</th>\n",
       "      <th>essay3</th>\n",
       "      <th>essay4</th>\n",
       "      <th>essay5</th>\n",
       "      <th>essay6</th>\n",
       "      <th>essay7</th>\n",
       "      <th>essay8</th>\n",
       "      <th>essay9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>59941</th>\n",
       "      <td>vibrant, expressive, caring optimist. i love b...</td>\n",
       "      <td>the happiest times have been when life came to...</td>\n",
       "      <td>i make an outstanding osso bucco. i am also ve...</td>\n",
       "      <td>i am told that people notice my smile, eyes an...</td>\n",
       "      <td>i am an avid movie watcher and follow the broa...</td>\n",
       "      <td>my family, my dog, italy, words and music!</td>\n",
       "      <td>writing my book.</td>\n",
       "      <td>running with my dog, finishing up the work wee...</td>\n",
       "      <td>i have a dream to sing at the alconquin in nyc...</td>\n",
       "      <td>you are seeking a long term connection of shar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59942</th>\n",
       "      <td>i'm nick. i never know what to write about mys...</td>\n",
       "      <td>currently finishing school for film production...</td>\n",
       "      <td>filmmaking, photography, graphic design, web d...</td>\n",
       "      <td>dude, i don't know.</td>\n",
       "      <td>movies: hook (the greatest adventure ever!), g...</td>\n",
       "      <td>iphone contact lenses headphones camera tv rem...</td>\n",
       "      <td>i do most of my thinking on the bus to/from wo...</td>\n",
       "      <td>bringin' home bacon, or drinking and shakin'!</td>\n",
       "      <td>when i was 18 i got a tattoo of waldo somewher...</td>\n",
       "      <td>meh if you made it this far you might as well.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59943</th>\n",
       "      <td>hello! i enjoy traveling, watching movies, and...</td>\n",
       "      <td>i'm a civil engineer, who enjoys helping the c...</td>\n",
       "      <td>- looking at things objectively - getting thin...</td>\n",
       "      <td>i'm quiet until i get used to the environment ...</td>\n",
       "      <td>last book: \"game change\". movies: bourne serie...</td>\n",
       "      <td>- iphone - friends and family - internet - bay...</td>\n",
       "      <td>aside from work, how to improve my home.</td>\n",
       "      <td>out enjoying friendly conversation over dinner.</td>\n",
       "      <td>please let me think about this more.</td>\n",
       "      <td>we have similar interests.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59944</th>\n",
       "      <td>\"all i have in this world are my balls and my ...</td>\n",
       "      <td>following my dreams... \"you got a dream... you...</td>\n",
       "      <td>listening</td>\n",
       "      <td>it used to be the hair until i mowed it off bu...</td>\n",
       "      <td>where to begin musically: right now i listen t...</td>\n",
       "      <td>music, family, friends, a basketball, hoop, so...</td>\n",
       "      <td>what can i do to make someone chuckle....</td>\n",
       "      <td>what i would do on any other day. everydays a ...</td>\n",
       "      <td>i like walking around in other people's house ...</td>\n",
       "      <td>you are interested and interesting...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59945</th>\n",
       "      <td>is it odd that having a little \"enemy\" status ...</td>\n",
       "      <td>i work with elderly people (psychotherapy and ...</td>\n",
       "      <td>i'm a great bullshitter. i don't know what it ...</td>\n",
       "      <td>either that i am funny/sarcastic, or that i am...</td>\n",
       "      <td>i just read the help by kathryn stockett, sooo...</td>\n",
       "      <td>1. family &amp; friends &amp; other humans - interacti...</td>\n",
       "      <td>sex, myself, other people, how amazing everyth...</td>\n",
       "      <td>out at happy hour with my friends, running int...</td>\n",
       "      <td>i wish i could cry like holly hunter in broadc...</td>\n",
       "      <td>if you have a back-bone, an opinion, a sense o...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  essay0  \\\n",
       "59941  vibrant, expressive, caring optimist. i love b...   \n",
       "59942  i'm nick. i never know what to write about mys...   \n",
       "59943  hello! i enjoy traveling, watching movies, and...   \n",
       "59944  \"all i have in this world are my balls and my ...   \n",
       "59945  is it odd that having a little \"enemy\" status ...   \n",
       "\n",
       "                                                  essay1  \\\n",
       "59941  the happiest times have been when life came to...   \n",
       "59942  currently finishing school for film production...   \n",
       "59943  i'm a civil engineer, who enjoys helping the c...   \n",
       "59944  following my dreams... \"you got a dream... you...   \n",
       "59945  i work with elderly people (psychotherapy and ...   \n",
       "\n",
       "                                                  essay2  \\\n",
       "59941  i make an outstanding osso bucco. i am also ve...   \n",
       "59942  filmmaking, photography, graphic design, web d...   \n",
       "59943  - looking at things objectively - getting thin...   \n",
       "59944                                          listening   \n",
       "59945  i'm a great bullshitter. i don't know what it ...   \n",
       "\n",
       "                                                  essay3  \\\n",
       "59941  i am told that people notice my smile, eyes an...   \n",
       "59942                                dude, i don't know.   \n",
       "59943  i'm quiet until i get used to the environment ...   \n",
       "59944  it used to be the hair until i mowed it off bu...   \n",
       "59945  either that i am funny/sarcastic, or that i am...   \n",
       "\n",
       "                                                  essay4  \\\n",
       "59941  i am an avid movie watcher and follow the broa...   \n",
       "59942  movies: hook (the greatest adventure ever!), g...   \n",
       "59943  last book: \"game change\". movies: bourne serie...   \n",
       "59944  where to begin musically: right now i listen t...   \n",
       "59945  i just read the help by kathryn stockett, sooo...   \n",
       "\n",
       "                                                  essay5  \\\n",
       "59941         my family, my dog, italy, words and music!   \n",
       "59942  iphone contact lenses headphones camera tv rem...   \n",
       "59943  - iphone - friends and family - internet - bay...   \n",
       "59944  music, family, friends, a basketball, hoop, so...   \n",
       "59945  1. family & friends & other humans - interacti...   \n",
       "\n",
       "                                                  essay6  \\\n",
       "59941                                   writing my book.   \n",
       "59942  i do most of my thinking on the bus to/from wo...   \n",
       "59943           aside from work, how to improve my home.   \n",
       "59944          what can i do to make someone chuckle....   \n",
       "59945  sex, myself, other people, how amazing everyth...   \n",
       "\n",
       "                                                  essay7  \\\n",
       "59941  running with my dog, finishing up the work wee...   \n",
       "59942      bringin' home bacon, or drinking and shakin'!   \n",
       "59943    out enjoying friendly conversation over dinner.   \n",
       "59944  what i would do on any other day. everydays a ...   \n",
       "59945  out at happy hour with my friends, running int...   \n",
       "\n",
       "                                                  essay8  \\\n",
       "59941  i have a dream to sing at the alconquin in nyc...   \n",
       "59942  when i was 18 i got a tattoo of waldo somewher...   \n",
       "59943               please let me think about this more.   \n",
       "59944  i like walking around in other people's house ...   \n",
       "59945  i wish i could cry like holly hunter in broadc...   \n",
       "\n",
       "                                                  essay9  \n",
       "59941  you are seeking a long term connection of shar...  \n",
       "59942     meh if you made it this far you might as well.  \n",
       "59943                         we have similar interests.  \n",
       "59944              you are interested and interesting...  \n",
       "59945  if you have a back-bone, an opinion, a sense o...  "
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "profiles.tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "severe-organizer",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sustituir valores nan por '' \n",
    "profiles.fillna(\" \", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "temporal-philippines",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>all_essays</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>about me:  i would love to think that i was so...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i am a chef: this is what that means. 1. i am ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i'm not ashamed of much, but writing public te...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i work in a library and go to school. . . read...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hey how's it going? currently vague on the pro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59941</th>\n",
       "      <td>vibrant, expressive, caring optimist. i love b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59942</th>\n",
       "      <td>i'm nick. i never know what to write about mys...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59943</th>\n",
       "      <td>hello! i enjoy traveling, watching movies, and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59944</th>\n",
       "      <td>\"all i have in this world are my balls and my ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59945</th>\n",
       "      <td>is it odd that having a little \"enemy\" status ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>59946 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              all_essays\n",
       "0      about me:  i would love to think that i was so...\n",
       "1      i am a chef: this is what that means. 1. i am ...\n",
       "2      i'm not ashamed of much, but writing public te...\n",
       "3      i work in a library and go to school. . . read...\n",
       "4      hey how's it going? currently vague on the pro...\n",
       "...                                                  ...\n",
       "59941  vibrant, expressive, caring optimist. i love b...\n",
       "59942  i'm nick. i never know what to write about mys...\n",
       "59943  hello! i enjoy traveling, watching movies, and...\n",
       "59944  \"all i have in this world are my balls and my ...\n",
       "59945  is it odd that having a little \"enemy\" status ...\n",
       "\n",
       "[59946 rows x 1 columns]"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Unificacion de todos los essays a una sola columna\n",
    "essays = []\n",
    "essays = profiles.essay0 + ' ' + profiles.essay1 + ' ' + profiles.essay2 + ' ' + profiles.essay3 + ' ' + profiles.essay4 + ' ' + profiles.essay5 + ' ' + profiles.essay6 + ' ' + profiles.essay7 + ' ' + profiles.essay8 + ' ' + profiles.essay9\n",
    "profiles['all_essays'] = essays\n",
    "\n",
    "if \"essay1\" in profiles.columns:\n",
    "    profiles.drop(columns=essaysname, inplace=True)\n",
    "\n",
    "if (profiles.isnull().sum().to_list() == []): \n",
    "    print(\"No hay nulos\")\n",
    "    \n",
    "profiles "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "advised-sewing",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_words = ['still','take','trying','great','go','little','live','good','big','years','love','right','back','mine','thing','things',\n",
    "             'better','anything','really','able','half','made','way','make','someone','everything','kind','see','type','types','new',\n",
    "             'more','much','lot','though','unless','probably','usually','looking','also','something','know','think','like','enjoy',\n",
    "             'well','time','making','always','try','one','would','around','many','making','going','want','trying','open','long',\n",
    "             'pretty','say','sometimes','getting','best','stuff','person','day','favorite','feel','old','smile','guy','life','living',\n",
    "             'afluster', 'dfg', 'eleifend', 'emfoi', 'ewoe', 'faucibus', 'fgd', 'frakking', 'fsd', 'fsdf', 'ghtr', 'hilda', 'imm',\n",
    "             'maecenas', 'mafoiawm', 'malesuada', 'moewaaoicmw', 'moiwa', 'mweiof', 'nn', 'oma', 'pharetra', 'praline', 'rg', 'rth',\n",
    "             'saah', 'sdf', 'sfd', 'thous', 'torolf', 'utm', 'wahh', 'woi', 'wordsi', 'yuval','aoicmw', 'bhakti', 'bluetoonist', 'citation',\n",
    "             'curabitur', 'dfgd', 'epr', 'gosto', 'gsdsd', 'hallie', 'inhabitable', 'lobortis', 'lorelai', 'lorry', 'lovebot', 'luctus',\n",
    "             'mdmj', 'moewa', 'ner', 'pandit', 'prema', 'proident', 'realmente', 'rgd', 'sfsd', 'sgi', 'slats', 'sugalumps',\n",
    "             'superintendent', 'teehehe', 'tramps', 'ustad', 'varius', 'vulputate', 'yew', 'annun', 'artsier', 'autobus',\n",
    "             'congue', 'enfjs', 'eplariza', 'exercitation', 'fru', 'gatorar', 'gazelle', 'godhead', 'incididunt', 'infps',\n",
    "             'jrpg', 'kenner', 'kielbasa', 'lipps', 'meep', 'messi', 'motherflippin', 'nfnc', 'nostrud', 'ralston', 'ratkins',\n",
    "             'roiphe', 'ruffin', 'rutrum', 'saraswati', 'sifu', 'stefisbuff', 'strongbow', 'suscipit', 'tili', 'unst', 'walla', 'aliqua',\n",
    "             'aliquip', 'andouille', 'apna', 'ashzra', 'auch', 'congruence', 'cupidatat', 'demisexual', 'dolore', 'ecoutez', 'elly', 'frnds',\n",
    "             'fuckups', 'fuk', 'kladdkaka', 'klove', 'laboris', 'lov', 'lupus', 'melia', 'nao', 'omnicircus', 'paciocco', 'quidam', 'rere',\n",
    "             'setters', 'sharpens', 'singe', 'sint', 'teksto', 'thaat', 'tribunal', 'waaahh', 'wawah', 'aglets', 'akashic', 'belladonna', 'boingy',\n",
    "             'breatharian', 'buk', 'cafepress', 'cyclenator', 'ecopsychology', 'esse', 'excetera', 'fnordloki', 'fortran', 'gado', 'hoon',\n",
    "             'horsey', 'krylon', 'lawton', 'noc', 'occitan', 'officia', 'orale', 'pawns', 'pwc', 'ql', 'reactivity', 'rutgers', 'sexanddesign',\n",
    "             'slocks', 'thoe', 'toga', 'tudi', 'voluptate', 'wedged', 'zander','adipisicing', 'alota', 'arnall', 'arrr', 'babygirl',\n",
    "             'bjrn', 'chanchito', 'consonant', 'dob', 'dunh', 'duval', 'eyeware', 'ftapon', 'gallbladder', 'guiltied', 'gust', 'haulin',\n",
    "             'jetzt', 'kma', 'lili', 'matchy', 'melinda', 'moocow', 'muzix', 'mysore', 'oshun', 'porttitor', 'prendre', 'rnr', 'saige',\n",
    "             'sattvic', 'tabor', 'tartan', 'teaspoons', 'unemotional','aanq', 'aku', 'alg', 'allister', 'aoi', 'debrief', 'estar', 'felling',\n",
    "             'fw', 'guyana', 'hilbert', 'hornier', 'humin', 'jjc', 'joyfulparadox', 'larm', 'layne', 'livros', 'maj', 'mii', 'muziq', 'newsstand',\n",
    "             'nullalux', 'oooooooooaaaaaaawwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwww',\n",
    "             'peices', 'pitted', 'quelque', 'resently', 'rly', 'sleeeeeping', 'supplementation', 'topher', 'tristissima', 'viel', 'virgule', 'people','world', 'fun', 'work', 'working']\n",
    "\n",
    "stopwords_customized = stopwords.words('english') + new_words + list(ENGLISH_STOP_WORDS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "terminal-brunswick",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    review = re.sub(r'\\W', ' ', text) #sentences[i]     # Sustituye los caracteres no alfanuméricos por espacio\n",
    "    review = review.lower()                             # Conversion a minusculas\n",
    "    review = re.sub(r'^br$', ' ', review)               # Los que empiecen por 'b' y terminen por 'r' se sustituyen por un espacio en blanco\n",
    "    review = re.sub(r'\\s+br\\s+',' ',review)             # El patron (espacio en blanco o más, br, espacio en blanco o mas) se sustituye por un espacio en blanco\n",
    "    review = re.sub(r'\\s+[a-z]\\s+', ' ',review)         # El patron (espacio en blanco o más, cualquier letra del alfabeto, espacio en blanco o más) se sustituye por un espacio en blanco\n",
    "    review = re.sub(r'^b\\s+', '', review)               # Comienzo de la cadena con 'b' seguido de uno o mas espacios en blanco lo elimina\n",
    "    review = re.sub(r'\\s+', ' ', review)                # Eliminar los espacios en blanco sobrantes incluidos en los pasos anteriores.\n",
    "    review = re.sub('[^a-zA-Z]+', ' ', review)\n",
    "    #corpus.append(review)r'\\s+'\n",
    "    return review\n",
    "\n",
    "def tokenize(text):\n",
    "    sentences = nltk.sent_tokenize(text)\n",
    "    return sentences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "usual-input",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "59946"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fusion = []\n",
    "for i in range(len(essays)):\n",
    "    fusion.append(preprocess_text(essays[i]))\n",
    "len(fusion)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "working-doctor",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(59946, 10)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Convert a collection of text documents to a matrix of token counts\n",
    "vectorizer = CountVectorizer(max_features = 20, min_df = 0.25, max_df = 0.85, stop_words = stopwords_customized ) #Convert a collection of text documents to a matrix of token counts\n",
    "X = vectorizer.fit_transform(fusion).toarray()\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "metric-rolling",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'reading': 9,\n",
       " 'books': 0,\n",
       " 'movies': 6,\n",
       " 'music': 7,\n",
       " 'food': 2,\n",
       " 'friends': 3,\n",
       " 'read': 8,\n",
       " 'movie': 5,\n",
       " 'family': 1,\n",
       " 'home': 4}"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "progressive-economics",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['books', 'family', 'food', 'friends', 'home', 'movie', 'movies', 'music', 'read', 'reading']\n"
     ]
    }
   ],
   "source": [
    "# Mostrar las características.\n",
    "features = vectorizer.get_feature_names()\n",
    "print(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "nasty-monitor",
   "metadata": {},
   "outputs": [],
   "source": [
    "######LDA\n",
    "# Obtener los temas.\n",
    "n_topics = 4\n",
    "lda = LatentDirichletAllocation(n_components=n_topics, random_state=123)\n",
    "my_docs_topic = lda.fit_transform(X)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "popular-parliament",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.03689712, 0.32303481, 0.60387851, 0.03618957],\n",
       "       [0.12777698, 0.12540162, 0.620254  , 0.1265674 ],\n",
       "       [0.50949537, 0.27760066, 0.02624686, 0.18665711],\n",
       "       ...,\n",
       "       [0.48125781, 0.02014014, 0.34803398, 0.15056807],\n",
       "       [0.61785289, 0.31298927, 0.0367009 , 0.03245695],\n",
       "       [0.22491138, 0.55071749, 0.1153142 , 0.10905693]])"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_docs_topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "close-simon",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_composition = lda.components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "unique-victoria",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_top = 4\n",
    "for i in range(n_topics):\n",
    "    topic_features = [features[idx] for idx in np.argsort(-topic_composition[i,:])]   # argsort() muestra el índice ordenado.\n",
    "    topic_features_top = topic_features[0:n_top]\n",
    "    if i == 0:\n",
    "        topic_matrix = [topic_features_top]                    # list의 list 만들 준비!\n",
    "    else:\n",
    "        topic_matrix.append(topic_features_top) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "worth-responsibility",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['friends', 'family', 'food', 'music'],\n",
       " ['read', 'reading', 'books', 'movies'],\n",
       " ['music', 'food', 'movies', 'books'],\n",
       " ['home', 'movie', 'friends', 'family']]"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Muestra las características principales de cada tema.\n",
    "topic_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "contained-sample",
   "metadata": {},
   "outputs": [],
   "source": [
    "# En vista de las características principales, podemos nombrar los temas.\n",
    "topic_names = ['Social','Book','Music','Movie']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "cognitive-valve",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essays</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Music</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Music</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Social</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Book</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Music</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59941</th>\n",
       "      <td>Movie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59942</th>\n",
       "      <td>Music</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59943</th>\n",
       "      <td>Social</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59944</th>\n",
       "      <td>Social</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59945</th>\n",
       "      <td>Book</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>59946 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       essays\n",
       "0       Music\n",
       "1       Music\n",
       "2      Social\n",
       "3        Book\n",
       "4       Music\n",
       "...       ...\n",
       "59941   Movie\n",
       "59942   Music\n",
       "59943  Social\n",
       "59944  Social\n",
       "59945    Book\n",
       "\n",
       "[59946 rows x 1 columns]"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# El tema más probable viene dado directamente por la salida de LDA.\n",
    "n_docs = len(essays)\n",
    "labels = []\n",
    "for i in range(n_docs):\n",
    "    topic_pick = np.argmax(my_docs_topic[i,:])\n",
    "    #print(\"Document \" + str(i+1) + \" = \" + topic_names[topic_pick])\n",
    "    labels.append(topic_names[topic_pick])\n",
    "    \n",
    "#Nueva columna en pandas con las etiquetas\n",
    "profiles['essays'] = labels    \n",
    "if \"all_essays\" in profiles.columns.to_list():\n",
    "    profiles.drop(columns=\"all_essays\", inplace=True)\n",
    "profiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "numeric-thumbnail",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Join by index with our dataset\n",
    "df = pd.merge(df, profiles, left_index=True, right_index=True)\n",
    "df.drop(columns = [\"essay\"+str(i) for i in range(0,10)], inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "maritime-controversy",
   "metadata": {},
   "source": [
    "## Construir Dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "speaking-confidentiality",
   "metadata": {},
   "source": [
    "### Categoricas Obligatorias: Separar en datasets \n",
    "- Homosexual mujer (Bisexual mujer)\n",
    "- Homosexual hombre (Bisuxeal hombre)\n",
    "- Heterosexuales (Bisexual)\n",
    "\n",
    "En todas podemos borrar sex menos en heterosexual\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "atlantic-world",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['m', 'f'], dtype=object)"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"sex\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "accomplished-composer",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['straight', 'bisexual', 'gay'], dtype=object)"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"orientation\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "forbidden-prefix",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/iciac/.local/lib/python3.8/site-packages/pandas/core/frame.py:4163: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().drop(\n"
     ]
    }
   ],
   "source": [
    "homosexual_f = df[(\"f\" == dataset[\"sex\"]) & (dataset[\"orientation\"].isin([\"bisexual\", \"gay\"]))]\n",
    "homosexual_h = df[(\"m\" == dataset[\"sex\"]) & (dataset[\"orientation\"].isin([\"bisexual\", \"gay\"]))]\n",
    "heterosexual = df[(dataset[\"orientation\"].isin([\"bisexual\", \"straight\"]))]\n",
    "\n",
    "homosexual_f.drop(columns = [\"sex\",\"orientation\"], inplace = True)\n",
    "homosexual_h.drop(columns = [\"sex\",\"orientation\"], inplace = True)\n",
    "heterosexual.drop(columns = [\"orientation\"], inplace = True)\n",
    "\n",
    "homosexual_f.to_csv(path_actual+\"/dataset/homosexualf.csv\", index= False)\n",
    "homosexual_h.to_csv(path_actual+\"/dataset/homosexualh.csv\", index= False)\n",
    "heterosexual.to_csv(path_actual+\"/dataset/heterosexual.csv\", index= False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
